{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from machine_learning import MachineLearning\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descripteur_porter = pd.read_csv('freq_poids_porter.csv')\n",
    "df_descripteur_lancaster = pd.read_csv('freq_poids_lancaster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freqs_poids_porter = pd.read_csv('freq_poids_porter.csv')\n",
    "df_freqs_poids_lancaster = pd.read_csv('freq_poids_lancaster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_dbscan = pd.read_csv('pca_df_dbscan.csv').drop(['label', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_porter = pd.read_csv('queries_porter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents = 1460\n",
      "18 Editions of the Dewey Decimal Classifications The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n",
      "\n",
      "\n",
      "Number of queries = 112\n",
      "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
      "\n",
      "\n",
      "Number of mappings = 76\n",
      "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
     ]
    }
   ],
   "source": [
    "ml = MachineLearning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old files (Deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inverse_porter = pd.read_csv('df_poids.csv').drop('Unnamed: 0', axis=1)\n",
    "# df_inverse_lancaster = pd.read_csv('df_poids_lan.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First tab functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_poids(phrase, stemming_method):\n",
    "        if stemming_method == 'Porter':\n",
    "                return ml.freq_inverse(df_descripteur_porter, phrase, 'P')\n",
    "        elif stemming_method == 'Lancaster':\n",
    "                return ml.freq_inverse(df_descripteur_lancaster, phrase, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_document_number(document, stemming_method):\n",
    "        if stemming_method == 'Porter':\n",
    "                new_df = df_descripteur_porter[df_descripteur_porter['Document']== document]\n",
    "        elif stemming_method == 'Lancaster':\n",
    "                new_df = df_descripteur_lancaster[df_descripteur_lancaster['Document']== document]\n",
    "        new_df.drop(['Document'], axis=1, inplace=True)\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old functions (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_document_descripteur(document, stemming_method):\n",
    "#         if stemming_method == 'Porter':\n",
    "#                 new_df = df_descripteur_porter[df_descripteur_porter['Document']== document]\n",
    "#         elif stemming_method == 'Lancaster':\n",
    "#                 new_df = df_descripteur_lancaster[df_descripteur_lancaster['Document']== document]\n",
    "#         new_df.drop(['Document'], axis=1, inplace=True)\n",
    "        \n",
    "#         if stemming_method == 'Porter':\n",
    "#                 inverse = df_inverse_porter.iloc[int(document)].to_frame()\n",
    "#         elif stemming_method == 'Lancaster':\n",
    "#                 inverse = df_inverse_lancaster.iloc[int(document)].to_frame()\n",
    "#         inverse = inverse[(inverse.T != 0.000000).all()]\n",
    "#         inverse = inverse.reset_index(level=0)\n",
    "#         inverse[\"Terme\"] = inverse[\"index\"]\n",
    "#         inverse[\"Poid\"] = inverse[int(document)]\n",
    "#         inverse.drop([int(document)], axis=1, inplace=True)\n",
    "#         inverse.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "#         return [new_df, inverse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_document_inverse(phrase, stemming_method):\n",
    "#         ExpReg = nltk. RegexpTokenizer('(?:[A-Za-z]\\.)+|\\d+(?:\\.\\d+)?%?|\\w+(?:\\-\\w+)*')\n",
    "#         termes = ExpReg.tokenize(phrase)\n",
    "#         termes = [t.lower() for t in termes]\n",
    "#         MotsVides = nltk.corpus.stopwords.words('english')\n",
    "#         if stemming_method == 'Porter':\n",
    "#                 Porter = nltk.PorterStemmer()\n",
    "#                 TermesSansMotsVides_p = [Porter.stem(terme) for terme in termes if terme.lower() not in MotsVides]\n",
    "#         elif stemming_method == 'Lancaster':\n",
    "#                 Lancaster = nltk.LancasterStemmer()\n",
    "#                 TermesSansMotsVides_p = [Lancaster.stem(terme) for terme in termes if terme.lower() not in MotsVides]\n",
    "        \n",
    "#         if stemming_method == 'Porter':\n",
    "#                 new_df = df_inverse_porter[TermesSansMotsVides_p]\n",
    "#         elif stemming_method == 'Lancaster':\n",
    "#                 new_df = df_inverse_lancaster[TermesSansMotsVides_p]\n",
    "#         new_df = new_df[(new_df.T != 0.000000).any()]\n",
    "#         new_df = new_df.reset_index(level=0)\n",
    "\n",
    "#         if stemming_method == 'Porter':\n",
    "#                 desc_df = df_descripteur_porter.loc[df_descripteur_porter['Terme'].isin(TermesSansMotsVides_p) ]\n",
    "#         elif stemming_method == 'Lancaster':\n",
    "#                 desc_df = df_descripteur_lancaster.loc[df_descripteur_lancaster['Terme'].isin(TermesSansMotsVides_p) ]\n",
    "\n",
    "#         #new_df.drop(['document'], axis=1, inplace=True)\n",
    "#         return new_df, desc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second tab function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(query, stemmer):\n",
    "        results = ml.boolean(query, stemmer[0])\n",
    "        return pd.DataFrame(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_query(\"information AND classification OR NOT title AND computers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third tab functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dbscan_function(eps, min_samples):\n",
    "        global X\n",
    "        X = df_pca_dbscan.copy()\n",
    "        dbscan = ml.DBSCAN(eps, min_samples, data=df_pca_dbscan.to_numpy())\n",
    "        dbscan.fit()\n",
    "        X['label'] = np.nan\n",
    "        clusters = dbscan.get_clusters()\n",
    "        noise = dbscan.get_noise()\n",
    "        for cluster in range (len(clusters)):\n",
    "                for element in clusters[cluster]:\n",
    "                        #assign cluster number to each element\n",
    "                        X.loc[element]['label'] = cluster\n",
    "        for element in noise:\n",
    "                #assign cluster number to each element\n",
    "                X.loc[element]['label'] = -1\n",
    "        fig,ax = plt.subplots(1,1)\n",
    "        map = ax.scatter(X['0'],X['1'], c=X['label'], cmap='rainbow')\n",
    "        fig.colorbar(map, ax=ax)\n",
    "        res, plot_naive, plot_naive_scatter,confusion_matrix_naive, accuracy, precision, recall, f1 = run_naive_bayes()\n",
    "        \n",
    "        return fig, plot_naive, plot_naive_scatter, confusion_matrix_naive, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naive_bayes():\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(queries_porter)\n",
    "        x_pca = pca.transform(queries_porter)\n",
    "        pca_df = pd.DataFrame(x_pca)\n",
    "        x = pca_df.values #returns a numpy array\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        pca_df_normalized = pd.DataFrame(x_scaled)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = ml.train_test_split(X, test_size=0.3)\n",
    "        bayes= ml.NaiveBayesClassifier()\n",
    "        bayes.fit(X_train, y_train)\n",
    "        predictions = bayes.predict(X_test.squeeze())\n",
    "        while (len(np.unique(predictions)) < len(np.unique(X['label']))/2):\n",
    "            X_train, X_test, y_train, y_test = ml.train_test_split(X, test_size=0.3)\n",
    "            bayes= ml.NaiveBayesClassifier()\n",
    "            bayes.fit(X_train, y_train)\n",
    "            predictions = bayes.predict(X_test.squeeze())\n",
    "\n",
    "        accuracy = bayes.accuracy(y_test, predictions)\n",
    "\n",
    "        plot_naive = bayes.visualize(y_test, predictions, 'label')\n",
    "\n",
    "        pca_df_normalized['label'] = bayes.predict(pca_df_normalized)\n",
    "        fig2, ax = plt.subplots(1,1)\n",
    "        ax.scatter(pca_df_normalized[0], pca_df_normalized[1], c=pca_df_normalized['label'], cmap='rainbow')\n",
    "        \n",
    "        predictions = pd.Series(predictions)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        confusion = bayes.confusion_matrix(y_test, predictions)\n",
    "        precision = pd.DataFrame(bayes.precision(y_test, predictions), columns=['Precision'])\n",
    "        recall = pd.DataFrame(bayes.recall(y_test, predictions), columns=['Recall'])\n",
    "        f1 = pd.DataFrame(bayes.f1_score(y_test, predictions), columns=['F1 Score'])\n",
    "        return bayes, plot_naive, fig2, confusion, accuracy, precision, recall, f1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = run_dbscan_function(0.022221,7)\n",
    "# type(res[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Tab Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(combo_queries, stemming_method_evaluation, SRI):\n",
    "        query_idx = combo_queries.split(':')[0]\n",
    "        \n",
    "        res = ml.roc_curve(stemming_method_evaluation[0], int(query_idx), SRI)\n",
    "        # roc_curve, top10, p5, p10, p5_inter, p10_inter\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.plot(res['Rappel_Interpolée'], res['Precision_Interpolée'])\n",
    "        return fig, res, res['Precision'].iloc[4], res['Precision'].iloc[9], res['Precision_Interpolée'].iloc[4], res['Precision_Interpolée'].iloc[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(ml.qry_set.items())\n",
    "queries[:] = [f\"{elem[0]}: \"+elem[1][:50] +\"...\" for elem in queries]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://59877f98-84d9-4767.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://59877f98-84d9-4767.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\routes.py\", line 327, in run_predict\n",
      "    iterators=iterators,\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 857, in call_function\n",
      "    block_fn.fn, *processed_input, limiter=self.limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\to_thread.py\", line 32, in run_sync\n",
      "    func, *args, cancellable=cancellable, limiter=limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"<ipython-input-18-27ee14e6539a>\", line 4, in run_evaluation\n",
      "    res = ml.roc_curve(stemming_method_evaluation[0], int(query_idx), SRI)\n",
      "  File \"c:\\Users\\YsPC\\Documents\\GitHub\\RI\\Projet-RI\\machine_learning.py\", line 414, in roc_curve\n",
      "    docs['Distance'].loc[doc-1] = self._distance(pca_df_normalized_queries.loc[query-1,0:1],docs.loc[doc-1][0:2].values)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 873, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1044, in _getitem_tuple\n",
      "    return self._getitem_lowerdim(tup)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 810, in _getitem_lowerdim\n",
      "    return getattr(section, self.name)[new_key]\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1088, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1123, in _get_slice_axis\n",
      "    slice_obj.start, slice_obj.stop, slice_obj.step, kind=\"loc\"\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 4969, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step, kind=kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5172, in slice_locs\n",
      "    start_slice = self.get_slice_bound(start, \"left\", kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5082, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side, kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5034, in _maybe_cast_slice_bound\n",
      "    self._invalid_indexer(\"slice\", label)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 3271, in _invalid_indexer\n",
      "    f\"cannot do {form} indexing on {type(self).__name__} with these \"\n",
      "TypeError: cannot do slice indexing on Index with these indexers [0] of type int\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\routes.py\", line 327, in run_predict\n",
      "    iterators=iterators,\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 857, in call_function\n",
      "    block_fn.fn, *processed_input, limiter=self.limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\to_thread.py\", line 32, in run_sync\n",
      "    func, *args, cancellable=cancellable, limiter=limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"<ipython-input-18-27ee14e6539a>\", line 4, in run_evaluation\n",
      "    res = ml.roc_curve(stemming_method_evaluation[0], int(query_idx), SRI)\n",
      "  File \"c:\\Users\\YsPC\\Documents\\GitHub\\RI\\Projet-RI\\machine_learning.py\", line 414, in roc_curve\n",
      "    docs['Distance'].loc[doc-1] = self._distance(pca_df_normalized_queries.loc[query-1,0:1],docs.loc[doc-1][0:2].values)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 873, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1044, in _getitem_tuple\n",
      "    return self._getitem_lowerdim(tup)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 810, in _getitem_lowerdim\n",
      "    return getattr(section, self.name)[new_key]\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1088, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1123, in _get_slice_axis\n",
      "    slice_obj.start, slice_obj.stop, slice_obj.step, kind=\"loc\"\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 4969, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step, kind=kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5172, in slice_locs\n",
      "    start_slice = self.get_slice_bound(start, \"left\", kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5082, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side, kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5034, in _maybe_cast_slice_bound\n",
      "    self._invalid_indexer(\"slice\", label)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 3271, in _invalid_indexer\n",
      "    f\"cannot do {form} indexing on {type(self).__name__} with these \"\n",
      "TypeError: cannot do slice indexing on Index with these indexers [0] of type int\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d582a4f6ebc4a899fd7afe0b6774635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\routes.py\", line 327, in run_predict\n",
      "    iterators=iterators,\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 857, in call_function\n",
      "    block_fn.fn, *processed_input, limiter=self.limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\to_thread.py\", line 32, in run_sync\n",
      "    func, *args, cancellable=cancellable, limiter=limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"<ipython-input-18-27ee14e6539a>\", line 4, in run_evaluation\n",
      "    res = ml.roc_curve(stemming_method_evaluation[0], int(query_idx), SRI)\n",
      "  File \"c:\\Users\\YsPC\\Documents\\GitHub\\RI\\Projet-RI\\machine_learning.py\", line 414, in roc_curve\n",
      "    docs['Distance'].loc[doc-1] = self._distance(pca_df_normalized_queries.loc[query-1,0:1],docs.loc[doc-1][0:2].values)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 873, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1044, in _getitem_tuple\n",
      "    return self._getitem_lowerdim(tup)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 810, in _getitem_lowerdim\n",
      "    return getattr(section, self.name)[new_key]\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1088, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1123, in _get_slice_axis\n",
      "    slice_obj.start, slice_obj.stop, slice_obj.step, kind=\"loc\"\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 4969, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step, kind=kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5172, in slice_locs\n",
      "    start_slice = self.get_slice_bound(start, \"left\", kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5082, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side, kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5034, in _maybe_cast_slice_bound\n",
      "    self._invalid_indexer(\"slice\", label)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 3271, in _invalid_indexer\n",
      "    f\"cannot do {form} indexing on {type(self).__name__} with these \"\n",
      "TypeError: cannot do slice indexing on Index with these indexers [0] of type int\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\routes.py\", line 327, in run_predict\n",
      "    iterators=iterators,\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 857, in call_function\n",
      "    block_fn.fn, *processed_input, limiter=self.limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\to_thread.py\", line 32, in run_sync\n",
      "    func, *args, cancellable=cancellable, limiter=limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"<ipython-input-18-27ee14e6539a>\", line 4, in run_evaluation\n",
      "    res = ml.roc_curve(stemming_method_evaluation[0], int(query_idx), SRI)\n",
      "  File \"c:\\Users\\YsPC\\Documents\\GitHub\\RI\\Projet-RI\\machine_learning.py\", line 414, in roc_curve\n",
      "    docs['Distance'].loc[doc-1] = self._distance(pca_df_normalized_queries.loc[query-1,0:1],docs.loc[doc-1][0:2].values)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 873, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1044, in _getitem_tuple\n",
      "    return self._getitem_lowerdim(tup)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 810, in _getitem_lowerdim\n",
      "    return getattr(section, self.name)[new_key]\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1088, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1123, in _get_slice_axis\n",
      "    slice_obj.start, slice_obj.stop, slice_obj.step, kind=\"loc\"\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 4969, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step, kind=kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5172, in slice_locs\n",
      "    start_slice = self.get_slice_bound(start, \"left\", kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5082, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side, kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5034, in _maybe_cast_slice_bound\n",
      "    self._invalid_indexer(\"slice\", label)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 3271, in _invalid_indexer\n",
      "    f\"cannot do {form} indexing on {type(self).__name__} with these \"\n",
      "TypeError: cannot do slice indexing on Index with these indexers [0] of type int\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\routes.py\", line 327, in run_predict\n",
      "    iterators=iterators,\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 857, in call_function\n",
      "    block_fn.fn, *processed_input, limiter=self.limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\to_thread.py\", line 32, in run_sync\n",
      "    func, *args, cancellable=cancellable, limiter=limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"<ipython-input-18-27ee14e6539a>\", line 4, in run_evaluation\n",
      "    res = ml.roc_curve(stemming_method_evaluation[0], int(query_idx), SRI)\n",
      "  File \"c:\\Users\\YsPC\\Documents\\GitHub\\RI\\Projet-RI\\machine_learning.py\", line 414, in roc_curve\n",
      "    docs['Distance'].loc[doc-1] = self._distance(pca_df_normalized_queries.loc[query-1,0:1],docs.loc[doc-1][0:2].values)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 873, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1044, in _getitem_tuple\n",
      "    return self._getitem_lowerdim(tup)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 810, in _getitem_lowerdim\n",
      "    return getattr(section, self.name)[new_key]\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1088, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1123, in _get_slice_axis\n",
      "    slice_obj.start, slice_obj.stop, slice_obj.step, kind=\"loc\"\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 4969, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step, kind=kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5172, in slice_locs\n",
      "    start_slice = self.get_slice_bound(start, \"left\", kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5082, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side, kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5034, in _maybe_cast_slice_bound\n",
      "    self._invalid_indexer(\"slice\", label)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 3271, in _invalid_indexer\n",
      "    f\"cannot do {form} indexing on {type(self).__name__} with these \"\n",
      "TypeError: cannot do slice indexing on Index with these indexers [0] of type int\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\routes.py\", line 327, in run_predict\n",
      "    iterators=iterators,\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gradio\\blocks.py\", line 857, in call_function\n",
      "    block_fn.fn, *processed_input, limiter=self.limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\to_thread.py\", line 32, in run_sync\n",
      "    func, *args, cancellable=cancellable, limiter=limiter\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"<ipython-input-18-27ee14e6539a>\", line 4, in run_evaluation\n",
      "    res = ml.roc_curve(stemming_method_evaluation[0], int(query_idx), SRI)\n",
      "  File \"c:\\Users\\YsPC\\Documents\\GitHub\\RI\\Projet-RI\\machine_learning.py\", line 414, in roc_curve\n",
      "    docs['Distance'].loc[doc-1] = self._distance(pca_df_normalized_queries.loc[query-1,0:1],docs.loc[doc-1][0:2].values)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 873, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1044, in _getitem_tuple\n",
      "    return self._getitem_lowerdim(tup)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 810, in _getitem_lowerdim\n",
      "    return getattr(section, self.name)[new_key]\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 879, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1088, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py\", line 1123, in _get_slice_axis\n",
      "    slice_obj.start, slice_obj.stop, slice_obj.step, kind=\"loc\"\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 4969, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step, kind=kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5172, in slice_locs\n",
      "    start_slice = self.get_slice_bound(start, \"left\", kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5082, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side, kind)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 5034, in _maybe_cast_slice_bound\n",
      "    self._invalid_indexer(\"slice\", label)\n",
      "  File \"C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\", line 3271, in _invalid_indexer\n",
      "    f\"cannot do {form} indexing on {type(self).__name__} with these \"\n",
      "TypeError: cannot do slice indexing on Index with these indexers [0] of type int\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "        gr.Markdown(\"main app\")\n",
    "        with gr.Tab(\"Main Searches\"):\n",
    "                with gr.Row():\n",
    "                        with gr.Column():\n",
    "                                gr.Markdown(\"Search by Term\")\n",
    "                                search_input = gr.Textbox(label=\"Search for terms\")\n",
    "                                search_button = gr.Button(label=\"Search by Term\")\n",
    "                with gr.Row():\n",
    "                        with gr.Column():\n",
    "                                gr.Markdown(\"Search by Document\")\n",
    "                                search_document = gr.Number()\n",
    "                        with gr.Column():\n",
    "                                gr.Markdown(\"Stemming method\")\n",
    "                                stemming_method = gr.Radio([\"Porter\", \"Lancaster\"], label=\"Stemming\")\n",
    "                        search_document_button = gr.Button(label=\"Search by Document\")\n",
    "                with gr.Row():\n",
    "                        search_output = gr.Numpy()\n",
    "\n",
    "        with gr.Tab(\"Boolean Search\"):\n",
    "                gr.Markdown(\"Boolean Search\")\n",
    "                search_boolean = gr.Textbox(label=\"Boolean search\")\n",
    "                stemmer_boolean = gr.Radio([\"Porter\", \"Lancaster\"], label=\"Stemming\")\n",
    "                search_boolean_button = gr.Button(label=\"Search\")\n",
    "                search_boolean_output = gr.Numpy()\n",
    "        with gr.Tab(\"DBScan\"):\n",
    "                gr.Markdown(\"DBScan\")\n",
    "                with gr.Row():\n",
    "                        with gr.Column():\n",
    "                                plot_dbscan = gr.Plot()\n",
    "                        with gr.Column():\n",
    "                                eps = gr.Number()\n",
    "                                min_samples = gr.Number()\n",
    "                                run_dbscan = gr.Button(label=\"Run DBScan\")\n",
    "        with gr.Tab(\"Naive Bayes\"):\n",
    "                gr.Markdown(\"Naive Bayes\")\n",
    "                plot_naive = gr.Plot()\n",
    "                with gr.Row():\n",
    "                        with gr.Column():\n",
    "                                plot_naive_scatter = gr.Plot()\n",
    "                        with gr.Column():\n",
    "                                accuracy = gr.Textbox(label = 'Accuracy')\n",
    "                with gr.Row():\n",
    "                        with gr.Column():\n",
    "                                precision = gr.Numpy()\n",
    "                        with gr.Column():\n",
    "                                recall = gr.Numpy()\n",
    "                        with gr.Column():\n",
    "                                f1 = gr.Numpy()\n",
    "                with gr.Row():\n",
    "                        confusion_matrix_naive = gr.Numpy()\n",
    "                \n",
    "        with gr.Tab(\"Evaluation\"):\n",
    "                gr.Markdown(\"Evaluation\")\n",
    "                with gr.Row():\n",
    "                        with gr.Column():\n",
    "                                roc_curve = gr.Plot()\n",
    "                                run_eval = gr.Button(label=\"Run Evaluation\")\n",
    "                        with gr.Column():\n",
    "                                combo_queries = gr.Dropdown(queries)\n",
    "                                with gr.Row():\n",
    "                                        stemming_method_evaluation = gr.Radio([\"Porter\", \"Lancaster\"], label=\"Stemming\")\n",
    "                                with gr.Row():\n",
    "                                        SRI = gr.Radio([\"Cosine\", \"Jaccard\", \"BM25\", \"Produit Scalaire\", \"Datamining\"], label = \"SRI\")\n",
    "                with gr.Row():\n",
    "                        top10 = gr.Numpy()\n",
    "                with gr.Row():\n",
    "                        with gr.Column():\n",
    "                                p5 = gr.Textbox(label = 'p@5')\n",
    "                                p10 = gr.Textbox(label = 'p@10')\n",
    "                        with gr.Column():\n",
    "                                p5_inter = gr.Textbox(label = 'p@5 interpolée')\n",
    "                                p10_inter = gr.Textbox(label = 'p@10_interpolée')\n",
    "\n",
    "\n",
    "        search_button.click(search_query_poids, inputs = [search_input, stemming_method], outputs = search_output)\n",
    "        search_document_button.click(search_document_number, inputs = [search_document, stemming_method], outputs = search_output)\n",
    "        search_boolean_button.click(search_query, inputs = [search_boolean, stemmer_boolean], outputs = search_boolean_output)\n",
    "        run_dbscan.click(run_dbscan_function, inputs = [eps, min_samples], outputs = [plot_dbscan, plot_naive, plot_naive_scatter, confusion_matrix_naive, accuracy, precision, recall, f1])\n",
    "        run_eval.click(run_evaluation, inputs = [combo_queries, stemming_method_evaluation, SRI], outputs = [roc_curve, top10, p5, p10, p5_inter, p10_inter])\n",
    "        \n",
    "\n",
    "app.launch(share = 'False')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef545868ebe32c0c19943cd724395eaefc95151b54bafda088e747bf03113afe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
